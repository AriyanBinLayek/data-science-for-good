{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import smac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ConfigSpace and different types of parameters\n",
    "from smac.configspace import ConfigurationSpace\n",
    "from ConfigSpace.hyperparameters import (CategoricalHyperparameter, \n",
    "                                         NormalFloatHyperparameter,\n",
    "                                            UniformFloatHyperparameter, \n",
    "            UniformIntegerHyperparameter, \n",
    "            IntegerHyperparameter)\n",
    "from ConfigSpace.conditions import InCondition\n",
    "\n",
    "# Import SMAC-utilities\n",
    "from smac.tae.execute_func import ExecuteTAFuncDict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smac.scenario.scenario import Scenario\n",
    "from smac.facade.smac_facade import SMAC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from timeit import default_timer as timer\n",
    "import lightgbm as lgb\n",
    "from hyperopt import hp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (572) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "features = pd.read_csv('data/ft_2000_important.csv')\n",
    "submit_base = pd.read_csv('data/test.csv')[['Id', 'idhogar']]\n",
    "\n",
    "train = features[features['Target'].notnull()].copy()\n",
    "test = features[features['Target'].isnull()].copy()\n",
    "\n",
    "train_labels = np.array(train.pop('Target'))\n",
    "test_ids = list(test.pop('idhogar'))\n",
    "\n",
    "train, test = train.align(test, join = 'inner', axis = 1)\n",
    "\n",
    "features = pd.read_csv('data/ft_2000_important.csv')\n",
    "submit_base = pd.read_csv('data/test.csv')[['Id', 'idhogar']]\n",
    "\n",
    "train = features[features['Target'].notnull()].copy()\n",
    "test = features[features['Target'].isnull()].copy()\n",
    "\n",
    "train_labels = np.array(train.pop('Target'))\n",
    "test_ids = list(test.pop('idhogar'))\n",
    "\n",
    "train, test = train.align(test, join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space\n",
    "space = {\n",
    "    'boosting_type': hp.choice('boosting_type', \n",
    "                              [{'boosting_type': 'gbdt', \n",
    "                                'subsample': hp.uniform('gdbt_subsample', 0.5, 1),\n",
    "                                'subsample_freq': hp.quniform('gbdt_subsample_freq', 1, 10, 1)}, \n",
    "                               {'boosting_type': 'dart', \n",
    "                                 'subsample': hp.uniform('dart_subsample', 0.5, 1),\n",
    "                                 'subsample_freq': hp.quniform('dart_subsample_freq', 1, 10, 1),\n",
    "                                 'drop_rate': hp.uniform('dart_drop_rate', 0.1, 0.5)},\n",
    "                                {'boosting_type': 'goss',\n",
    "                                 'subsample': 1.0,\n",
    "                                 'subsample_freq': 0}]),\n",
    "    'limit_max_depth': hp.choice('limit_max_depth', [True, False]),\n",
    "    'max_depth': hp.quniform('max_depth', 1, 40, 1),\n",
    "    'num_leaves': hp.quniform('num_leaves', 3, 50, 1),\n",
    "    'learning_rate': hp.loguniform('learning_rate', \n",
    "                                   np.log(0.025), \n",
    "                                   np.log(0.25)),\n",
    "    'subsample_for_bin': hp.quniform('subsample_for_bin', 2000, 100000, 2000),\n",
    "    'min_child_samples': hp.quniform('min_child_samples', 5, 80, 5),\n",
    "    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n",
    "    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n",
    "    'colsample_bytree': hp.uniform('colsample_by_tree', 0.5, 1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting_type': {'boosting_type': 'dart',\n",
       "  'drop_rate': 0.14096616663541625,\n",
       "  'subsample': 0.9238708887637695,\n",
       "  'subsample_freq': 9.0},\n",
       " 'colsample_bytree': 0.8818559103073851,\n",
       " 'learning_rate': 0.03509027454510622,\n",
       " 'limit_max_depth': False,\n",
       " 'max_depth': 22.0,\n",
       " 'min_child_samples': 55.0,\n",
       " 'num_leaves': 11.0,\n",
       " 'reg_alpha': 0.8414587667651955,\n",
       " 'reg_lambda': 0.5327558904022563,\n",
       " 'subsample_for_bin': 2000.0}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from hyperopt.pyll.stochastic import sample\n",
    "\n",
    "sample(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_score(labels, predictions):\n",
    "    # Reshape the predictions as needed\n",
    "    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n",
    "    \n",
    "    metric_value = f1_score(labels, predictions, average = 'macro')\n",
    "    \n",
    "    # Return is name, value, is_higher_better\n",
    "    return 'macro_f1', metric_value, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(hyperparameters):\n",
    "    \"\"\"Return validation score from hyperparameters for LightGBM\"\"\"\n",
    "    \n",
    "    # Keep track of evals\n",
    "#     global ITERATION\n",
    "#     ITERATION += 1\n",
    "    \n",
    "    # Retrieve the subsample\n",
    "    # subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n",
    "    # subsample_freq = hyperparameters['boosting_type'].get('subsample_freq', 0)\n",
    "    \n",
    "    hyperparameters = {k : hyperparameters[k] for k in hyperparameters if hyperparameters[k]}\n",
    "    \n",
    "    limit_max_depth = hyperparameters['limit_max_depth']\n",
    "    \n",
    "    if limit_max_depth == 'false':\n",
    "        del hyperparameters['max_depth']\n",
    "    \n",
    "#     boosting_type = hyperparameters['boosting_type']\n",
    "    \n",
    "#     # Use drop rate with dart\n",
    "#     if boosting_type == 'dart':\n",
    "#         hyperparameters['drop_rate'] = hyperparameters['boosting_type']['drop_rate']\n",
    "        \n",
    "    # Assign subsample and subsample freq to top level keys\n",
    "#     hyperparameters['boosting_type'] = boosting_type\n",
    "#     hyperparameters['subsample'] = subsample\n",
    "#     hyperparameters['subsample_freq'] = subsample_freq\n",
    "    \n",
    "    # Make sure parameters that need to be integers are integers\n",
    "    for parameter_name in ['num_leaves', 'subsample_for_bin', \n",
    "                           'min_child_samples', 'subsample_freq']:\n",
    "        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n",
    "\n",
    "    if 'n_estimators' in hyperparameters:\n",
    "        del hyperparameters['n_estimators']\n",
    "    \n",
    "    # Using stratified kfold cross validation\n",
    "    strkfold = StratifiedKFold(n_splits = 5, shuffle = True)\n",
    "    \n",
    "    # Convert to arrays for indexing\n",
    "    features = np.array(train)\n",
    "    labels = np.array(train_labels).reshape((-1 ))\n",
    "    \n",
    "    valid_scores = []\n",
    "    best_estimators = []\n",
    "    run_times = []\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**hyperparameters, class_weight = 'balanced',\n",
    "                               n_jobs=-1, metric = 'None',\n",
    "                               n_estimators=10000)\n",
    "    \n",
    "    # Iterate through the folds\n",
    "    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n",
    "        \n",
    "        # Training and validation data\n",
    "        X_train = features[train_indices]\n",
    "        X_valid = features[valid_indices]\n",
    "        y_train = labels[train_indices]\n",
    "        y_valid = labels[valid_indices]\n",
    "        \n",
    "        start = timer()\n",
    "        # Train with early stopping\n",
    "        model.fit(X_train, y_train, early_stopping_rounds = 100, \n",
    "                  eval_metric = macro_f1_score, \n",
    "                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
    "                  eval_names = ['train', 'valid'],\n",
    "                  verbose = 400)\n",
    "        end = timer()\n",
    "        # Record the validation fold score\n",
    "        valid_scores.append(model.best_score_['valid']['macro_f1'])\n",
    "        best_estimators.append(model.best_iteration_)\n",
    "        \n",
    "        run_times.append(end - start)\n",
    "    \n",
    "    score = np.mean(valid_scores)\n",
    "    score_std = np.std(valid_scores)\n",
    "    loss = 1 - score\n",
    "    \n",
    "    run_time = np.mean(run_times)\n",
    "    run_time_std = np.std(run_times)\n",
    "    \n",
    "    estimators = int(np.mean(best_estimators))\n",
    "    # hyperparameters['n_estimators'] = estimators\n",
    "    print(type(hyperparameters))\n",
    "    # Write to the csv file ('a' means append)\n",
    "#     of_connection = open(OUT_FILE, 'a')\n",
    "#     writer = csv.writer(of_connection)\n",
    "#     writer.writerow([loss, hyperparameters, ITERATION, run_time, score, score_std])\n",
    "#     of_connection.close()\n",
    "    \n",
    "#     # Display progress\n",
    "#     if ITERATION % PROGRESS == 0:\n",
    "#         display(f'Iteration: {ITERATION}, Current Score: {round(score, 4)}.')\n",
    "    \n",
    "#     return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "#             'time': run_time, 'time_std': run_time_std, 'status': STATUS_OK, \n",
    "#             'score': score, 'score_std': score_std}\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "drop_rate | boosting_type in {'dart'}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosting_type = CategoricalHyperparameter('boosting_type',\n",
    "                                          ['goss', 'dart', 'gbdt'],\n",
    "                                          default_value = 'dart')\n",
    "\n",
    "limit_max_depth = CategoricalHyperparameter('limit_max_depth', \n",
    "                                            ['true', 'false'])\n",
    "\n",
    "max_depth = UniformIntegerHyperparameter('max_depth', 1, 40)\n",
    "\n",
    "num_leaves = UniformIntegerHyperparameter('num_leaves', 3, 50)\n",
    "\n",
    "\n",
    "learning_rate = UniformFloatHyperparameter('learning_rate', \n",
    "                                     0.025, 0.25)\n",
    "\n",
    "subsample_for_bin = UniformIntegerHyperparameter('subsample_for_bin', \n",
    "                                                 2000, 100000)\n",
    "\n",
    "min_child_samples = UniformIntegerHyperparameter('min_child_samples', 5, 80,\n",
    "                                                 default_value = 10)\n",
    "\n",
    "reg_alpha = UniformFloatHyperparameter('reg_alpha', 0.0, 1.0)\n",
    "reg_lambda = UniformFloatHyperparameter('reg_lambda', 0.0, 1.0)\n",
    "\n",
    "colsample_bytree = UniformFloatHyperparameter('colsample_bytree',\n",
    "                                              0.5, 1.0)\n",
    "\n",
    "\n",
    "subsample = UniformFloatHyperparameter('subsample', 0.5, 1.0,\n",
    "                                       default_value = 1.0)\n",
    "\n",
    "subsample_freq = UniformIntegerHyperparameter('subsample_freq', 1, 10,\n",
    "                                              default_value = None)\n",
    "\n",
    "drop_rate = UniformFloatHyperparameter('drop_rate', 0.1, 0.5)\n",
    "\n",
    "cs = ConfigurationSpace()\n",
    "\n",
    "cs.add_hyperparameters([boosting_type, limit_max_depth, max_depth, num_leaves, \n",
    "                        learning_rate, subsample_for_bin, min_child_samples,\n",
    "                        reg_alpha, reg_lambda, colsample_bytree, \n",
    "                        subsample, subsample_freq, drop_rate])\n",
    "\n",
    "cs.add_condition(InCondition(child=max_depth, parent=limit_max_depth,\n",
    "                             values = ['true']))\n",
    "\n",
    "cs.add_condition(InCondition(child=subsample, parent=boosting_type, \n",
    "                             values = ['gbdt', 'dart']))\n",
    "\n",
    "cs.add_condition(InCondition(child=subsample_freq, parent=boosting_type, \n",
    "                                            values = ['gbdt', 'dart']))\n",
    "\n",
    "cs.add_condition(InCondition(child=drop_rate, parent=boosting_type, \n",
    "                                            values = ['dart']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:smac.scenario.scenario.Scenario:Output to smac3-output_2018-08-16_21-11-49_148146\n"
     ]
    }
   ],
   "source": [
    "scenario = Scenario({\"run_obj\": \"quality\", \n",
    "                     \"runcount-limit\": 2,\n",
    "                     \"cs\": cs,\n",
    "                     \"deterministic\": \"true\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Configuration:\n",
       "  boosting_type, Value: 'dart'\n",
       "  colsample_bytree, Value: 0.75\n",
       "  drop_rate, Value: 0.3\n",
       "  learning_rate, Value: 0.1375\n",
       "  limit_max_depth, Value: 'true'\n",
       "  max_depth, Value: 20\n",
       "  min_child_samples, Value: 10\n",
       "  num_leaves, Value: 26\n",
       "  reg_alpha, Value: 0.5\n",
       "  reg_lambda, Value: 0.5\n",
       "  subsample, Value: 1.0\n",
       "  subsample_for_bin, Value: 51000\n",
       "  subsample_freq, Value: 6"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs.get_default_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[18]\ttrain's macro_f1: 0.828241\tvalid's macro_f1: 0.456539\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttrain's macro_f1: 0.95156\tvalid's macro_f1: 0.452733\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[260]\ttrain's macro_f1: 0.982592\tvalid's macro_f1: 0.424449\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttrain's macro_f1: 0.833188\tvalid's macro_f1: 0.408718\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttrain's macro_f1: 0.836999\tvalid's macro_f1: 0.424985\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "def_value = objective(cs.get_default_configuration())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5665151821143468"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing! Depending on your machine, this might take a few minutes.\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[139]\ttrain's macro_f1: 0.945695\tvalid's macro_f1: 0.435085\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[9]\ttrain's macro_f1: 0.775774\tvalid's macro_f1: 0.393466\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[81]\ttrain's macro_f1: 0.925549\tvalid's macro_f1: 0.440679\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttrain's macro_f1: 0.916037\tvalid's macro_f1: 0.451565\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[150]\ttrain's macro_f1: 0.95284\tvalid's macro_f1: 0.436933\n",
      "<class 'dict'>\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's macro_f1: 0.795286\tvalid's macro_f1: 0.447015\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[59]\ttrain's macro_f1: 0.896254\tvalid's macro_f1: 0.442472\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[60]\ttrain's macro_f1: 0.898062\tvalid's macro_f1: 0.439373\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[45]\ttrain's macro_f1: 0.876508\tvalid's macro_f1: 0.423328\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[10]\ttrain's macro_f1: 0.700527\tvalid's macro_f1: 0.426397\n",
      "<class 'dict'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:smac.intensification.intensification.Intensifier:Challenger (0.5643) is better than incumbent (0.5685) on 1 runs.\n",
      "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
      "INFO:smac.intensification.intensification.Intensifier:  boosting_type : 'dart' -> 'gbdt'\n",
      "INFO:smac.intensification.intensification.Intensifier:  colsample_bytree : 0.75 -> 0.75919495684058\n",
      "INFO:smac.intensification.intensification.Intensifier:  learning_rate : 0.1375 -> 0.1387213776530116\n",
      "INFO:smac.intensification.intensification.Intensifier:  max_depth : 20 -> 28\n",
      "INFO:smac.intensification.intensification.Intensifier:  min_child_samples : 10 -> 30\n",
      "INFO:smac.intensification.intensification.Intensifier:  num_leaves : 26 -> 16\n",
      "INFO:smac.intensification.intensification.Intensifier:  reg_alpha : 0.5 -> 0.6552779076340373\n",
      "INFO:smac.intensification.intensification.Intensifier:  reg_lambda : 0.5 -> 0.6539670570919799\n",
      "INFO:smac.intensification.intensification.Intensifier:  subsample : 1.0 -> 0.7215576765604051\n",
      "INFO:smac.intensification.intensification.Intensifier:  subsample_for_bin : 51000 -> 82111\n",
      "INFO:smac.intensification.intensification.Intensifier:  subsample_freq : 6 -> 1\n",
      "INFO:smac.stats.stats.Stats:##########################################################\n",
      "INFO:smac.stats.stats.Stats:Statistics:\n",
      "INFO:smac.stats.stats.Stats:#Incumbent changed: 1\n",
      "INFO:smac.stats.stats.Stats:#Target algorithm runs: 2 / 2.0\n",
      "INFO:smac.stats.stats.Stats:Used wallclock time: 588.69 / inf sec \n",
      "INFO:smac.stats.stats.Stats:Used target algorithm runtime: 588.50 / inf sec\n",
      "INFO:smac.stats.stats.Stats:##########################################################\n",
      "INFO:smac.facade.smac_facade.SMAC:Final Incumbent: Configuration:\n",
      "  boosting_type, Value: 'gbdt'\n",
      "  colsample_bytree, Value: 0.75919495684058\n",
      "  learning_rate, Value: 0.1387213776530116\n",
      "  limit_max_depth, Value: 'true'\n",
      "  max_depth, Value: 28\n",
      "  min_child_samples, Value: 30\n",
      "  num_leaves, Value: 16\n",
      "  reg_alpha, Value: 0.6552779076340373\n",
      "  reg_lambda, Value: 0.6539670570919799\n",
      "  subsample, Value: 0.7215576765604051\n",
      "  subsample_for_bin, Value: 82111\n",
      "  subsample_freq, Value: 1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[65]\ttrain's macro_f1: 0.917477\tvalid's macro_f1: 0.437435\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[69]\ttrain's macro_f1: 0.916964\tvalid's macro_f1: 0.462649\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[47]\ttrain's macro_f1: 0.866527\tvalid's macro_f1: 0.458876\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttrain's macro_f1: 0.908424\tvalid's macro_f1: 0.454158\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttrain's macro_f1: 0.941494\tvalid's macro_f1: 0.43612\n",
      "<class 'dict'>\n",
      "Optimized Value: 0.55\n"
     ]
    }
   ],
   "source": [
    "# Optimize, using a SMAC-object\n",
    "print(\"Optimizing! Depending on your machine, this might take a few minutes.\")\n",
    "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
    "             tae_runner=objective)\n",
    "\n",
    "incumbent = smac.optimize()\n",
    "\n",
    "inc_value = objective(incumbent)\n",
    "\n",
    "print(\"Optimized Value: %.2f\" % (inc_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:smac.scenario.scenario.Scenario:Output to smac3-output_2018-08-16_21-11-33_420397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Value: 0.03\n"
     ]
    }
   ],
   "source": [
    "# We load the iris-dataset (a widely used benchmark)\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "def svm_from_cfg(cfg):\n",
    "    \"\"\" Creates a SVM based on a configuration and evaluates it on the\n",
    "    iris-dataset using cross-validation.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    cfg: Configuration (ConfigSpace.ConfigurationSpace.Configuration)\n",
    "        Configuration containing the parameters.\n",
    "        Configurations are indexable!\n",
    "    Returns:\n",
    "    --------\n",
    "    A crossvalidated mean score for the svm on the loaded data-set.\n",
    "    \"\"\"\n",
    "    # For deactivated parameters, the configuration stores None-values.\n",
    "    # This is not accepted by the SVM, so we remove them.\n",
    "    cfg = {k : cfg[k] for k in cfg if cfg[k]}\n",
    "    # We translate boolean values:\n",
    "    cfg[\"shrinking\"] = True if cfg[\"shrinking\"] == \"true\" else False\n",
    "    # And for gamma, we set it to a fixed value or to \"auto\" (if used)\n",
    "    if \"gamma\" in cfg:\n",
    "        cfg[\"gamma\"] = cfg[\"gamma_value\"] if cfg[\"gamma\"] == \"value\" else \"auto\"\n",
    "        cfg.pop(\"gamma_value\", None)  # Remove \"gamma_value\"\n",
    "\n",
    "    clf = svm.SVC(**cfg, random_state=42)\n",
    "\n",
    "    scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "    return 1-np.mean(scores)  # Minimize!\n",
    "\n",
    "#logger = logging.getLogger(\"SVMExample\")\n",
    "logging.basicConfig(level=logging.INFO)  # logging.DEBUG for debug output\n",
    "\n",
    "# Build Configuration Space which defines all parameters and their ranges\n",
    "cs = ConfigurationSpace()\n",
    "\n",
    "# We define a few possible types of SVM-kernels and add them as \"kernel\" to our cs\n",
    "kernel = CategoricalHyperparameter(\"kernel\", [\"linear\", \"rbf\", \"poly\", \"sigmoid\"], default_value=\"poly\")\n",
    "cs.add_hyperparameter(kernel)\n",
    "\n",
    "# There are some hyperparameters shared by all kernels\n",
    "C = UniformFloatHyperparameter(\"C\", 0.001, 1000.0, default_value=1.0)\n",
    "shrinking = CategoricalHyperparameter(\"shrinking\", [\"true\", \"false\"], default_value=\"true\")\n",
    "cs.add_hyperparameters([C, shrinking])\n",
    "\n",
    "# Others are kernel-specific, so we can add conditions to limit the searchspace\n",
    "degree = UniformIntegerHyperparameter(\"degree\", 1, 5, default_value=3)     # Only used by kernel poly\n",
    "coef0 = UniformFloatHyperparameter(\"coef0\", 0.0, 10.0, default_value=0.0)  # poly, sigmoid\n",
    "cs.add_hyperparameters([degree, coef0])\n",
    "use_degree = InCondition(child=degree, parent=kernel, values=[\"poly\"])\n",
    "use_coef0 = InCondition(child=coef0, parent=kernel, values=[\"poly\", \"sigmoid\"])\n",
    "cs.add_conditions([use_degree, use_coef0])\n",
    "\n",
    "# This also works for parameters that are a mix of categorical and values from a range of numbers\n",
    "# For example, gamma can be either \"auto\" or a fixed float\n",
    "gamma = CategoricalHyperparameter(\"gamma\", [\"auto\", \"value\"], default_value=\"auto\")  # only rbf, poly, sigmoid\n",
    "gamma_value = UniformFloatHyperparameter(\"gamma_value\", 0.0001, 8, default_value=1)\n",
    "cs.add_hyperparameters([gamma, gamma_value])\n",
    "# We only activate gamma_value if gamma is set to \"value\"\n",
    "cs.add_condition(InCondition(child=gamma_value, parent=gamma, values=[\"value\"]))\n",
    "# And again we can restrict the use of gamma in general to the choice of the kernel\n",
    "cs.add_condition(InCondition(child=gamma, parent=kernel, values=[\"rbf\", \"poly\", \"sigmoid\"]))\n",
    "\n",
    "\n",
    "# Scenario object\n",
    "scenario = Scenario({\"run_obj\": \"quality\",   # we optimize quality (alternatively runtime)\n",
    "                     \"runcount-limit\": 200,  # maximum function evaluations\n",
    "                     \"cs\": cs,               # configuration space\n",
    "                     \"deterministic\": \"true\"\n",
    "                     })\n",
    "\n",
    "# Example call of the function\n",
    "# It returns: Status, Cost, Runtime, Additional Infos\n",
    "def_value = svm_from_cfg(cs.get_default_configuration())\n",
    "print(\"Default Value: %.2f\" % (def_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing! Depending on your machine, this might take a few minutes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0333\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0333\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0333\n",
      "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0267) is better than incumbent (0.0333) on 1 runs.\n",
      "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
      "INFO:smac.intensification.intensification.Intensifier:  C : 1.0 -> 10.939416021476587\n",
      "INFO:smac.intensification.intensification.Intensifier:  kernel : 'poly' -> 'linear'\n",
      "INFO:smac.intensification.intensification.Intensifier:  shrinking : 'true' -> 'false'\n",
      "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0200) is better than incumbent (0.0267) on 1 runs.\n",
      "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
      "INFO:smac.intensification.intensification.Intensifier:  C : 10.939416021476587 -> 5.171268459600582\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0200\n",
      "INFO:smac.intensification.intensification.Intensifier:Challenger (0.0133) is better than incumbent (0.0200) on 1 runs.\n",
      "INFO:smac.intensification.intensification.Intensifier:Changes in incumbent:\n",
      "INFO:smac.intensification.intensification.Intensifier:  C : 5.171268459600582 -> 3.612669126119433\n",
      "INFO:smac.intensification.intensification.Intensifier:  gamma : None -> 'auto'\n",
      "INFO:smac.intensification.intensification.Intensifier:  kernel : 'linear' -> 'rbf'\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "WARNING:smac.intensification.intensification.Intensifier:Challenger was the same as the current incumbent; Skipping challenger\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "INFO:smac.intensification.intensification.Intensifier:Updated estimated cost of incumbent on 1 runs: 0.0133\n",
      "WARNING:smac.intensification.intensification.Intensifier:Challenger was the same as the current incumbent; Skipping challenger\n",
      "INFO:smac.stats.stats.Stats:##########################################################\n",
      "INFO:smac.stats.stats.Stats:Statistics:\n",
      "INFO:smac.stats.stats.Stats:#Incumbent changed: 3\n",
      "INFO:smac.stats.stats.Stats:#Target algorithm runs: 200 / 200.0\n",
      "INFO:smac.stats.stats.Stats:Used wallclock time: 11.64 / inf sec \n",
      "INFO:smac.stats.stats.Stats:Used target algorithm runtime: 7.62 / inf sec\n",
      "INFO:smac.stats.stats.Stats:##########################################################\n",
      "INFO:smac.facade.smac_facade.SMAC:Final Incumbent: Configuration:\n",
      "  C, Value: 3.612669126119433\n",
      "  gamma, Value: 'auto'\n",
      "  kernel, Value: 'rbf'\n",
      "  shrinking, Value: 'false'\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Value: 0.01\n"
     ]
    }
   ],
   "source": [
    "# Optimize, using a SMAC-object\n",
    "print(\"Optimizing! Depending on your machine, this might take a few minutes.\")\n",
    "smac = SMAC(scenario=scenario, rng=np.random.RandomState(42),\n",
    "        tae_runner=svm_from_cfg)\n",
    "\n",
    "incumbent = smac.optimize()\n",
    "\n",
    "inc_value = svm_from_cfg(incumbent)\n",
    "\n",
    "print(\"Optimized Value: %.2f\" % (inc_value))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "validate() got an unexpected keyword argument 'output'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-0153c2be0911>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[1;31m#instance_mode='train+test',  # Defines what instances to validate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mrepetitions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m        \u001b[1;31m# Ignored, unless you set \"deterministic\" to \"false\" in line 95\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m               n_jobs=1)               # How many cores to use in parallel for optimization\n\u001b[0m",
      "\u001b[1;32mc:\\users\\willk\\onedrive\\documents\\smac3\\smac\\facade\\smac_facade.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, config_mode, instance_mode, repetitions, use_epm, n_jobs, backend)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \"\"\"\n\u001b[0;32m    444\u001b[0m         return self.solver.validate(config_mode, instance_mode, repetitions,\n\u001b[1;32m--> 445\u001b[1;33m                                     use_epm, n_jobs, backend)\n\u001b[0m\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_tae_runner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\willk\\onedrive\\documents\\smac3\\smac\\optimizer\\smbo.py\u001b[0m in \u001b[0;36mvalidate\u001b[1;34m(self, config_mode, instance_mode, repetitions, use_epm, n_jobs, backend)\u001b[0m\n\u001b[0;32m    297\u001b[0m                                         \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunhistory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m                                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintensifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtae_runner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 299\u001b[1;33m                                         output=new_rh_path)\n\u001b[0m\u001b[0;32m    300\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnew_rh\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: validate() got an unexpected keyword argument 'output'"
     ]
    }
   ],
   "source": [
    "# We can also validate our results (though this makes a lot more sense with instances)\n",
    "smac.validate(config_mode='inc',      # We can choose which configurations to evaluate\n",
    "              #instance_mode='train+test',  # Defines what instances to validate\n",
    "              repetitions=100,        # Ignored, unless you set \"deterministic\" to \"false\" in line 95\n",
    "              n_jobs=1)               # How many cores to use in parallel for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

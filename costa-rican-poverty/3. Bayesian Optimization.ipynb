{
  "cells": [
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b908724254210600566fb79b108bfaf344cbd605"
      },
      "cell_type": "code",
      "source": "!pip install lightgbm --install-option=--gpu\n",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/pip/commands/install.py:194: UserWarning: Disabling all use of wheels due to the use of --build-options / --global-options / --install-options.\n  cmdoptions.check_install_build_global(options)\nRequirement already satisfied: lightgbm in /opt/conda/lib/python3.6/site-packages\nRequirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightgbm)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from lightgbm)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from lightgbm)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a11a4a9a92130faf0f55658f580d3507d4988b47",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "# numpy and pandas for data manipulation\nimport numpy as np\nimport pandas as pd \n\n# Clearing up memory\nimport gc\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import Imputer\n\n# Modeling\nimport lightgbm as lgb\n\n# Evaluation of the model\nfrom sklearn.model_selection import KFold, train_test_split, StratifiedKFold\nfrom sklearn.metrics import roc_auc_score, f1_score\n\nfrom hyperopt import hp\nfrom hyperopt import tpe\nfrom hyperopt import Trials\nfrom hyperopt import fmin\n\nimport csv\nfrom hyperopt import STATUS_OK\nfrom timeit import default_timer as timer\n\nimport json\n\nimport ast\n\nimport json",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "8dae366985945483f0c08e346ccbec77d5e8b97d"
      },
      "cell_type": "code",
      "source": "train = pd.read_csv('../input/costa-rican-household-poverty-prediction/train.csv')\ntrain_valid_labels = train.loc[train['parentesco1'] == 1, ['idhogar', 'Target']].copy()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f1f098417de72e118d2acfeb67d13b22ce03dd6b"
      },
      "cell_type": "code",
      "source": "feature_matrix = pd.read_csv('../input/costa-rican-poverty-derived-data/ft_2000.csv', low_memory = False)\nfeature_matrix.shape",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": "(10307, 1355)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "84a4b64f352b83925f1d596697179231584a04b6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "feature_matrix['SUM(ind.rez_esc / escolari)'] = feature_matrix['SUM(ind.rez_esc / escolari)'].astype(np.float64)\nfeature_matrix['SUM(ind.age / escolari)'] = feature_matrix['SUM(ind.age / escolari)'].astype(np.float64)",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd9c1db48f70fd27dbd72f5179f38bc927229e9e"
      },
      "cell_type": "code",
      "source": "feature_matrix.columns[np.where(feature_matrix.dtypes == 'object')[0]]",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": "Index(['SUM(ind.escolari / rez_esc)', 'SUM(ind.age / rez_esc)', 'idhogar'], dtype='object')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "810b829cdbfd1efa0bee02c063d01a627e5d0d5a",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "missing_threshold = 0.95\ncorrelation_threshold = 0.99\n\nfeature_matrix = feature_matrix.replace({np.inf: np.nan, -np.inf:np.nan})\n\n# One hot encoding (if necessary)\nfeature_matrix = pd.get_dummies(feature_matrix)\nn_features_start = feature_matrix.shape[1]\nprint('Original shape: ', feature_matrix.shape)\n\n# Find missing and percentage\nmissing = pd.DataFrame(feature_matrix.isnull().sum())\nmissing['fraction'] = missing[0] / feature_matrix.shape[0]\nmissing.sort_values('fraction', ascending = False, inplace = True)\n\n# Missing above threshold\nmissing_cols = list(missing[missing['fraction'] > missing_threshold].index)\nn_missing_cols = len(missing_cols)\n\n# Remove missing columns\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in missing_cols]]\nprint('{} missing columns with threshold: {}.'.format(n_missing_cols, missing_threshold))\n\n# Zero variance\nunique_counts = pd.DataFrame(feature_matrix.nunique()).sort_values(0, ascending = True)\nzero_variance_cols = list(unique_counts[unique_counts[0] == 1].index)\nn_zero_variance_cols = len(zero_variance_cols)\n\n# Remove zero variance columns\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in zero_variance_cols]]\nprint('{} zero variance columns.'.format(n_zero_variance_cols))\n\n# Correlations\ncorr_matrix = feature_matrix.corr()\n\n# Extract the upper triangle of the correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k = 1).astype(np.bool))\n\n# Select the features with correlations above the threshold\n# Need to use the absolute value\nto_drop = [column for column in upper.columns if any(upper[column].abs() > correlation_threshold)]\n\nn_collinear = len(to_drop)\n\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in to_drop]]\nprint('{} collinear columns removed with correlation above {}.'.format(n_collinear,  correlation_threshold))\n\ntotal_removed = n_missing_cols + n_zero_variance_cols + n_collinear\n\nprint('Total columns removed: ', total_removed)\nprint('Shape after feature selection: {}.'.format(feature_matrix.shape))\n\n# Remove columns derived from the Target\ndrop_cols = []\nfor col in feature_matrix:\n    if col == 'Target':\n        pass\n    else:\n        if 'Target' in col:\n            drop_cols.append(col)\n\nfeature_matrix = feature_matrix[[x for x in feature_matrix if x not in drop_cols]]    \n\n# Extract out training and testing data\ntrain = feature_matrix[feature_matrix['Target'].notnull()]\ntest = feature_matrix[feature_matrix['Target'].isnull()]\n\ntrain_labels = np.array(train.pop('Target')).reshape((-1, ))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "c38c615a6051390d64abb1f4dddbec7e0dc8fd01"
      },
      "cell_type": "markdown",
      "source": "## Custom Evaluation Metric"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "4e2915cc5e7f5779a1fb2f6279b0023b0d12717c"
      },
      "cell_type": "code",
      "source": "def macro_f1_score(labels, predictions):\n    # Reshape the predictions as needed\n    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n    \n    metric_value = f1_score(labels, predictions, average = 'macro')\n    \n    # Return is name, value, is_higher_better\n    return 'macro_f1', metric_value, True",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "f0804fd22c0bc846fb3e46c565b7fc47a2880c57"
      },
      "cell_type": "markdown",
      "source": "# Cross Validation Scores"
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "f64aaab5660e0d972ac9793d748ecba1702bbbd5"
      },
      "cell_type": "code",
      "source": "def model_valid(model, features, labels, nfolds = 5, return_preds = False):\n    \"\"\"Model using the GBM and cross validation.\n       Trains with early stopping on each fold.\n       Hyperparameters probably need to be tuned.\"\"\"\n\n    # Using stratified kfold cross validation\n    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n    \n    # Convert to arrays for indexing\n    features = np.array(features)\n    labels = np.array(labels).reshape((-1 ))\n    \n    valid_scores = []\n    best_estimators = []\n    # Iterate through the folds\n    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n        # Training and validation data\n        X_train = features[train_indices]\n        X_valid = features[valid_indices]\n        y_train = labels[train_indices]\n        y_valid = labels[valid_indices]\n        \n        # Train with early stopping\n        model.fit(X_train, y_train, early_stopping_rounds = 100, \n                  eval_metric = macro_f1_score,\n                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n                  eval_names = ['train', 'valid'],\n                  verbose = 200)\n        \n        # Record the validation fold score\n        valid_scores.append(model.best_score_['valid']['macro_f1'])\n        best_estimators.append(model.best_iteration_)\n        \n    best_estimators = np.array(best_estimators)\n    valid_scores = np.array(valid_scores)\n    return valid_scores, best_estimators",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "aa2573d9c6766653dea1f91d7f52869dbeb715cc"
      },
      "cell_type": "markdown",
      "source": "## Objective Function to Minimize (F1 Cross Validation Loss)"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def objective(hyperparameters):\n    \"\"\"Objective function for Gradient Boosting Machine Hyperparameter Optimization.\n       Writes a new line to `outfile` on every iteration\"\"\"\n    \n    # Keep track of evals\n    global ITERATION\n    \n    ITERATION += 1\n    \n    # Using early stopping to find number of trees trained\n    if 'n_estimators' in hyperparameters:\n        del hyperparameters['n_estimators']\n    \n    # Retrieve the subsample\n    subsample = hyperparameters['boosting_type'].get('subsample', 1.0)\n    \n    # Extract the boosting type and subsample to top level keys\n    hyperparameters['boosting_type'] = hyperparameters['boosting_type']['boosting_type']\n    hyperparameters['subsample'] = subsample\n    \n    # Make sure parameters that need to be integers are integers\n    for parameter_name in ['num_leaves', 'subsample_for_bin', 'min_child_samples']:\n        hyperparameters[parameter_name] = int(hyperparameters[parameter_name])\n\n    # Will be selected with early stopping\n    hyperparameters['n_estimators'] = 10000\n    hyperparameters['class_weight'] = 'balanced'\n    # hyperparameters['device'] = 'gpu'\n    model = lgb.LGBMClassifier(**hyperparameters)\n    \n    start = timer()\n    valid_scores, best_estimators = model_valid(model, train, train_labels)\n    run_time = timer() - start\n    \n    # Extract the best score\n    best_score = valid_scores.mean()\n    best_std = valid_scores.std()\n    \n    # Loss must be minimized\n    loss = 1 - best_score\n    \n    # Boosting rounds that returned the highest cv score\n    n_estimators = int(best_estimators.mean())\n    \n    # Add the number of estimators to the hyperparameters\n    hyperparameters['n_estimators'] = n_estimators\n\n    # Write to the csv file ('a' means append)\n    of_connection = open(OUT_FILE, 'a')\n    writer = csv.writer(of_connection)\n    writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score, best_std])\n    of_connection.close()\n\n    # Dictionary with information for evaluation\n    return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n            'train_time': run_time, 'status': STATUS_OK}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "faab04de2a932f79fb32b0bb606e02221a462213"
      },
      "cell_type": "code",
      "source": "\"\"\"\nSearch Domain\n\"\"\"\n\n# Define the search space\nspace = {\n    'boosting_type': hp.choice('boosting_type', \n                                            [{'boosting_type': 'gbdt', 'subsample': hp.uniform('gdbt_subsample', 0.5, 1)}, \n                                             {'boosting_type': 'dart', 'subsample': hp.uniform('dart_subsample', 0.5, 1)},\n                                             {'boosting_type': 'goss', 'subsample': 1.0}]),\n    'num_leaves': hp.quniform('num_leaves', 5, 50, 1),\n    'learning_rate': hp.loguniform('learning_rate', np.log(0.015), np.log(0.5)),\n    'subsample_for_bin': hp.quniform('subsample_for_bin', 20000, 300000, 20000),\n    'min_child_samples': hp.quniform('min_child_samples', 10, 60, 5),\n    'reg_alpha': hp.uniform('reg_alpha', 0.0, 1.0),\n    'reg_lambda': hp.uniform('reg_lambda', 0.0, 1.0),\n    'colsample_bytree': hp.uniform('colsample_by_tree', 0.6, 1.0)\n}",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "1a0091c9706ce833cd0df56f29c59af2613d8cb8"
      },
      "cell_type": "code",
      "source": "# Record results\ntrials = Trials()\n\n# Create a file and open a connection\nOUT_FILE = 'optimization2.csv'\nof_connection = open(OUT_FILE, 'w')\nwriter = csv.writer(of_connection)\n\nMAX_EVALS = 100\nN_FOLDS = 5\nITERATION = 0\n\n# Write column names\nheaders = ['loss', 'hyperparameters', 'iteration', 'runtime', 'score', 'std']\nwriter.writerow(headers)\nof_connection.close()\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "6d6036a2ce320eeb6371327affa5034d3b0feb28",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "%%capture\nprint(\"Running Optimization for {} Trials.\".format(MAX_EVALS))\n\n# Run optimization\nbest = fmin(fn = objective, space = space, algo = tpe.suggest, trials = trials,\n            max_evals = MAX_EVALS)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "43b13e5e3035a15ccefdac8bd1b8c1ac1fbdfc22",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import json\n\n# Save the trial results\nwith open('trials.json', 'w') as f:\n    f.write(json.dumps(trials))\n\nprint(best)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "629a839f8f94f26ddbee053ef856f4f89551a64c"
      },
      "cell_type": "code",
      "source": "results = pd.read_csv(OUT_FILE, index_col = 0)\nresults = results.sort_values('score', ascending = False)\nresults.to_csv('sorted_optimization2.csv', index = False)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "000160db012d569ffc90f160adca38d91a7b775b"
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Evaluation of the model\n",
    "from sklearn.model_selection import KFold, train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\willk\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2728: DtypeWarning: Columns (572) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10307, 2016)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.read_csv('data/ft_2000_important.csv')\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_base = pd.read_csv('data/test.csv')[['Id', 'idhogar']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = features[features['Target'].notnull()].copy()\n",
    "test = features[features['Target'].isnull()].copy()\n",
    "\n",
    "train_labels = np.array(train.pop('Target'))\n",
    "test_ids = list(test.pop('idhogar'))\n",
    "\n",
    "train, test = train.align(test, join = 'inner', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train:\n",
    "    if train[c].dtype == 'object':\n",
    "        train[c] = train[c].astype(np.float32)\n",
    "        test[c] = test[c].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train objects:  Index([], dtype='object')\n",
      "Test objects:  Index([], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('Train objects: ', train.columns[np.where(train.dtypes == 'object')])\n",
    "print('Test objects: ', test.columns[np.where(test.dtypes == 'object')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindfoundry.optaas.client.client import OPTaaSClient\n",
    "\n",
    "with open('C:/Users/willk/OneDrive/Desktop/optaas_key.txt', 'r') as f:\n",
    "    api_key = str(f.read())\n",
    "    \n",
    "client = OPTaaSClient('https://optaas.mindfoundry.ai', api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mindfoundry.optaas.client.parameter import Distribution, CategoricalParameter,IntParameter, ChoiceParameter, NumericParameter, FloatParameter\n",
    "from mindfoundry.optaas.client.constraint import Constraint\n",
    "from mindfoundry.optaas.client.client import Goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def macro_f1_score(labels, predictions):\n",
    "    # Reshape the predictions as needed\n",
    "    predictions = predictions.reshape(len(np.unique(labels)), -1 ).argmax(axis = 0)\n",
    "    \n",
    "    metric_value = f1_score(labels, predictions, average = 'macro')\n",
    "    \n",
    "    # Return is name, value, is_higher_better\n",
    "    return 'macro_f1', metric_value, True\n",
    "\n",
    "def objective(num_leaves, learning_rate, boosting_type,\n",
    "                      subsample, subsample_for_bin, min_child_samples,\n",
    "                      reg_alpha, reg_lambda, colsample_bytree, nfolds=5):\n",
    "    \"\"\"Return validation score from hyperparameters for LightGBM\"\"\"\n",
    "\n",
    "    # Using stratified kfold cross validation\n",
    "    strkfold = StratifiedKFold(n_splits = nfolds, shuffle = True)\n",
    "    \n",
    "    # Convert to arrays for indexing\n",
    "    features = np.array(train)\n",
    "    labels = np.array(train_labels).reshape((-1 ))\n",
    "    \n",
    "    valid_scores = []\n",
    "    best_estimators = []\n",
    "    \n",
    "    model = lgb.LGBMClassifier(num_leaves=num_leaves, learning_rate=learning_rate,\n",
    "                               boosting_type=boosting_type, subsample=subsample,\n",
    "                               subsample_for_bin=subsample_for_bin, \n",
    "                               min_child_samples=min_child_samples,\n",
    "                               reg_alpha=reg_alpha, reg_lambda=reg_lambda, \n",
    "                               colsample_bytree=colsample_bytree,\n",
    "                               class_weight = 'balanced',\n",
    "                               n_jobs=-1, n_estimators=10000)\n",
    "    \n",
    "    # Iterate through the folds\n",
    "    for i, (train_indices, valid_indices) in enumerate(strkfold.split(features, labels)):\n",
    "        \n",
    "        # Training and validation data\n",
    "        X_train = features[train_indices]\n",
    "        X_valid = features[valid_indices]\n",
    "        y_train = labels[train_indices]\n",
    "        y_valid = labels[valid_indices]\n",
    "        \n",
    "        # Train with early stopping\n",
    "        model.fit(X_train, y_train, early_stopping_rounds = 100, \n",
    "                  eval_metric = macro_f1_score,\n",
    "                  eval_set = [(X_train, y_train), (X_valid, y_valid)],\n",
    "                  eval_names = ['train', 'valid'],\n",
    "                  verbose = 400)\n",
    "        \n",
    "        # Record the validation fold score\n",
    "        valid_scores.append(model.best_score_['valid']['macro_f1'])\n",
    "        best_estimators.append(model.best_iteration_)\n",
    "        \n",
    "    best_estimators = np.array(best_estimators)\n",
    "    valid_scores = np.array(valid_scores)\n",
    "    \n",
    "#     return valid_scores, best_estimators\n",
    "\n",
    "    # Write to the csv file ('a' means append)\n",
    "#     of_connection = open(OUT_FILE, 'a')\n",
    "#     writer = csv.writer(of_connection)\n",
    "#     writer.writerow([loss, hyperparameters, ITERATION, run_time, best_score, best_std])\n",
    "#     of_connection.close()\n",
    "\n",
    "    # Dictionary with information for evaluation\n",
    "#     return {'loss': loss, 'hyperparameters': hyperparameters, 'iteration': ITERATION,\n",
    "#             'train_time': run_time, 'status': STATUS_OK}\n",
    "\n",
    "    return valid_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "boosting_type = CategoricalParameter('boosting_type', \n",
    "                                     values = ['gbdt', 'dart', 'goss'], \n",
    "                                     id='boosting_type')\n",
    "\n",
    "num_leaves = IntParameter('num_leaves', minimum=3, \n",
    "                          maximum=50, id='num_leaves')\n",
    "\n",
    "learning_rate = FloatParameter('learning_rate', minimum=0.025, \n",
    "                               maximum=0.25, id='learning_rate',\n",
    "                               distribution=Distribution.LOGUNIFORM)\n",
    "\n",
    "subsample = FloatParameter('subsample', minimum=0.5, \n",
    "                           maximum=1.0, id='subsample')\n",
    "\n",
    "subsample_for_bin = IntParameter('subsample_for_bin', minimum=2000, \n",
    "                                 maximum=100000, id='subsample_for_bin')\n",
    "\n",
    "min_child_samples = IntParameter('min_child_samples', minimum=5, \n",
    "                                 maximum=80, id='min_child_samples')\n",
    "\n",
    "reg_alpha = FloatParameter('reg_alpha', minimum=0.0, \n",
    "                           maximum=1.0, id='reg_alpha')\n",
    "\n",
    "reg_lambda = FloatParameter('reg_lambda', minimum=0.0, \n",
    "                            maximum=1.0, id='reg_lambda')\n",
    "\n",
    "colsample_bytree = FloatParameter('colsample_bytree', minimum=0.5, \n",
    "                                  maximum=1.0, id='colsample_bytree')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_constraint = Constraint(when=boosting_type=='goss', \n",
    "                                  then=subsample==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = client.create_task(\n",
    "        title = 'Light GBM Opt',\n",
    "        goal = Goal.max,\n",
    "        parameters = [num_leaves, learning_rate, boosting_type,\n",
    "                      subsample, subsample_for_bin, min_child_samples,\n",
    "                      reg_alpha, reg_lambda, colsample_bytree],\n",
    "         constraints = [ Constraint(when=boosting_type=='goss', \n",
    "                                    then=subsample==1)],\n",
    "         target_score = 0.45\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running task \"Light GBM Opt\" for 10 iterations\n",
      "(or until target score 0.45 is reached)\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[24]\ttrain's multi_logloss: 0.518707\ttrain's macro_f1: 0.749626\tvalid's multi_logloss: 0.817886\tvalid's macro_f1: 0.407854\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[22]\ttrain's multi_logloss: 0.541917\ttrain's macro_f1: 0.734547\tvalid's multi_logloss: 0.867512\tvalid's macro_f1: 0.334719\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's multi_logloss: 0.50887\ttrain's macro_f1: 0.76704\tvalid's multi_logloss: 0.833868\tvalid's macro_f1: 0.382666\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[26]\ttrain's multi_logloss: 0.490726\ttrain's macro_f1: 0.781751\tvalid's multi_logloss: 0.838261\tvalid's macro_f1: 0.381592\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[29]\ttrain's multi_logloss: 0.461625\ttrain's macro_f1: 0.793111\tvalid's multi_logloss: 0.828392\tvalid's macro_f1: 0.332611\n",
      "Iteration: 0    Score: 0.3678886242917831\n",
      "Configuration: {'num_leaves': 26, 'learning_rate': 0.1375, 'boosting_type': 'gbdt', 'subsample': 0.75, 'subsample_for_bin': 51000, 'min_child_samples': 42, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'colsample_bytree': 0.75}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttrain's multi_logloss: 0.629415\ttrain's macro_f1: 0.575049\tvalid's multi_logloss: 0.814857\tvalid's macro_f1: 0.381949\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[38]\ttrain's multi_logloss: 0.626444\ttrain's macro_f1: 0.597765\tvalid's multi_logloss: 0.838448\tvalid's macro_f1: 0.341748\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[37]\ttrain's multi_logloss: 0.642721\ttrain's macro_f1: 0.581105\tvalid's multi_logloss: 0.794696\tvalid's macro_f1: 0.373972\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[46]\ttrain's multi_logloss: 0.600953\ttrain's macro_f1: 0.619492\tvalid's multi_logloss: 0.813575\tvalid's macro_f1: 0.392571\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[39]\ttrain's multi_logloss: 0.629414\ttrain's macro_f1: 0.581718\tvalid's multi_logloss: 0.824411\tvalid's macro_f1: 0.349609\n",
      "Iteration: 1    Score: 0.3679696104454188\n",
      "Configuration: {'num_leaves': 6, 'learning_rate': 0.13971331046890875, 'boosting_type': 'gbdt', 'subsample': 0.6867862359679726, 'subsample_for_bin': 50468, 'min_child_samples': 46, 'reg_alpha': 0.35901696556377904, 'reg_lambda': 0.30995486784427395, 'colsample_bytree': 0.7949745906590588}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[158]\ttrain's multi_logloss: 0.476873\ttrain's macro_f1: 0.790852\tvalid's multi_logloss: 0.8265\tvalid's macro_f1: 0.404276\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttrain's multi_logloss: 1.05354\ttrain's macro_f1: 0.480528\tvalid's multi_logloss: 1.10059\tvalid's macro_f1: 0.371742\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttrain's multi_logloss: 0.588027\ttrain's macro_f1: 0.678809\tvalid's multi_logloss: 0.810407\tvalid's macro_f1: 0.383459\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[1]\ttrain's multi_logloss: 1.36111\ttrain's macro_f1: 0.410176\tvalid's multi_logloss: 1.3635\tvalid's macro_f1: 0.358479\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttrain's multi_logloss: 1.33655\ttrain's macro_f1: 0.43746\tvalid's multi_logloss: 1.34068\tvalid's macro_f1: 0.392927\n",
      "Iteration: 2    Score: 0.3821766658485759\n",
      "Configuration: {'num_leaves': 20, 'learning_rate': 0.028112060228350364, 'boosting_type': 'gbdt', 'subsample': 0.9180617286587482, 'subsample_for_bin': 87848, 'min_child_samples': 69, 'reg_alpha': 0.5713491463768386, 'reg_lambda': 0.6658754159823824, 'colsample_bytree': 0.7342294558062559}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[12]\ttrain's multi_logloss: 0.575321\ttrain's macro_f1: 0.850824\tvalid's multi_logloss: 0.913093\tvalid's macro_f1: 0.369913\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's multi_logloss: 0.357666\ttrain's macro_f1: 0.919983\tvalid's multi_logloss: 0.834298\tvalid's macro_f1: 0.385111\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's multi_logloss: 0.326292\ttrain's macro_f1: 0.933891\tvalid's multi_logloss: 0.851213\tvalid's macro_f1: 0.395201\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[25]\ttrain's multi_logloss: 0.327432\ttrain's macro_f1: 0.926487\tvalid's multi_logloss: 0.828278\tvalid's macro_f1: 0.375103\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttrain's multi_logloss: 0.728263\ttrain's macro_f1: 0.801831\tvalid's multi_logloss: 0.954814\tvalid's macro_f1: 0.395853\n",
      "Iteration: 3    Score: 0.38423616382927483\n",
      "Configuration: {'num_leaves': 32, 'learning_rate': 0.1367330467196163, 'boosting_type': 'gbdt', 'subsample': 0.9401270934947106, 'subsample_for_bin': 15109, 'min_child_samples': 7, 'reg_alpha': 0.31889212978901593, 'reg_lambda': 0.2474039220607801, 'colsample_bytree': 0.5245135299851662}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttrain's multi_logloss: 0.610772\ttrain's macro_f1: 0.702212\tvalid's multi_logloss: 0.851698\tvalid's macro_f1: 0.396603\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[293]\ttrain's multi_logloss: 0.425217\ttrain's macro_f1: 0.860549\tvalid's multi_logloss: 0.842049\tvalid's macro_f1: 0.416479\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[66]\ttrain's multi_logloss: 0.735634\ttrain's macro_f1: 0.585737\tvalid's multi_logloss: 0.878276\tvalid's macro_f1: 0.404213\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[214]\ttrain's multi_logloss: 0.544218\ttrain's macro_f1: 0.768121\tvalid's multi_logloss: 0.810886\tvalid's macro_f1: 0.380242\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[116]\ttrain's multi_logloss: 0.658521\ttrain's macro_f1: 0.669804\tvalid's multi_logloss: 0.874866\tvalid's macro_f1: 0.402819\n",
      "Iteration: 4    Score: 0.40007107783884444\n",
      "Configuration: {'num_leaves': 31, 'learning_rate': 0.05024169456103213, 'boosting_type': 'dart', 'subsample': 0.7303465364947568, 'subsample_for_bin': 15136, 'min_child_samples': 51, 'reg_alpha': 0.32584103157294375, 'reg_lambda': 0.22691560711246916, 'colsample_bytree': 0.5016938185334444}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[4]\ttrain's multi_logloss: 0.949933\ttrain's macro_f1: 0.546751\tvalid's multi_logloss: 1.03144\tvalid's macro_f1: 0.392185\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's multi_logloss: 0.523683\ttrain's macro_f1: 0.743534\tvalid's multi_logloss: 0.806074\tvalid's macro_f1: 0.402278\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[20]\ttrain's multi_logloss: 0.546598\ttrain's macro_f1: 0.739943\tvalid's multi_logloss: 0.862938\tvalid's macro_f1: 0.373858\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[23]\ttrain's multi_logloss: 0.517926\ttrain's macro_f1: 0.73086\tvalid's multi_logloss: 0.81543\tvalid's macro_f1: 0.367278\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttrain's multi_logloss: 0.565238\ttrain's macro_f1: 0.701821\tvalid's multi_logloss: 0.821689\tvalid's macro_f1: 0.380811\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 5    Score: 0.3832819497590046\n",
      "Configuration: {'num_leaves': 12, 'learning_rate': 0.18768075950567517, 'boosting_type': 'gbdt', 'subsample': 0.9049309842188232, 'subsample_for_bin': 56892, 'min_child_samples': 18, 'reg_alpha': 0.92637735625629, 'reg_lambda': 0.05869914257710396, 'colsample_bytree': 0.7798977510580736}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttrain's multi_logloss: 0.507803\ttrain's macro_f1: 0.755871\tvalid's multi_logloss: 0.809192\tvalid's macro_f1: 0.421317\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[145]\ttrain's multi_logloss: 0.432586\ttrain's macro_f1: 0.845112\tvalid's multi_logloss: 0.82231\tvalid's macro_f1: 0.415182\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[163]\ttrain's multi_logloss: 0.433784\ttrain's macro_f1: 0.857511\tvalid's multi_logloss: 0.830553\tvalid's macro_f1: 0.382918\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[2]\ttrain's multi_logloss: 1.19504\ttrain's macro_f1: 0.444172\tvalid's multi_logloss: 1.20923\tvalid's macro_f1: 0.388242\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[43]\ttrain's multi_logloss: 0.586824\ttrain's macro_f1: 0.654874\tvalid's multi_logloss: 0.83547\tvalid's macro_f1: 0.392035\n",
      "Iteration: 6    Score: 0.39993898249734494\n",
      "Configuration: {'num_leaves': 49, 'learning_rate': 0.12869074167900119, 'boosting_type': 'dart', 'subsample': 0.5081441018154894, 'subsample_for_bin': 91270, 'min_child_samples': 45, 'reg_alpha': 0.6099910539348951, 'reg_lambda': 0.998195158501798, 'colsample_bytree': 0.6579320238693465}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttrain's multi_logloss: 0.610201\ttrain's macro_f1: 0.83604\tvalid's multi_logloss: 0.900033\tvalid's macro_f1: 0.348575\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[67]\ttrain's multi_logloss: 0.692491\ttrain's macro_f1: 0.802203\tvalid's multi_logloss: 0.917792\tvalid's macro_f1: 0.399828\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[98]\ttrain's multi_logloss: 0.661613\ttrain's macro_f1: 0.813934\tvalid's multi_logloss: 0.901252\tvalid's macro_f1: 0.402088\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttrain's multi_logloss: 0.673721\ttrain's macro_f1: 0.808161\tvalid's multi_logloss: 0.890216\tvalid's macro_f1: 0.371318\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[265]\ttrain's multi_logloss: 0.387301\ttrain's macro_f1: 0.902772\tvalid's multi_logloss: 0.866601\tvalid's macro_f1: 0.375892\n",
      "Iteration: 7    Score: 0.3795402868303879\n",
      "Configuration: {'num_leaves': 30, 'learning_rate': 0.03964413894981232, 'boosting_type': 'dart', 'subsample': 0.5082178944928457, 'subsample_for_bin': 60835, 'min_child_samples': 7, 'reg_alpha': 0.7471045618895586, 'reg_lambda': 0.060604114887186755, 'colsample_bytree': 0.700926819240747}\n",
      "\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttrain's multi_logloss: 1.20791\ttrain's macro_f1: 0.61825\tvalid's multi_logloss: 1.2488\tvalid's macro_f1: 0.359711\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttrain's multi_logloss: 0.564922\ttrain's macro_f1: 0.806078\tvalid's multi_logloss: 0.838847\tvalid's macro_f1: 0.433759\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[3]\ttrain's multi_logloss: 1.30328\ttrain's macro_f1: 0.581051\tvalid's multi_logloss: 1.31751\tvalid's macro_f1: 0.365798\n",
      "Training until validation scores don't improve for 100 rounds.\n"
     ]
    }
   ],
   "source": [
    "best_result, best_configuration = task.run(objective, max_iterations = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{ 'id': '68094917-5202-451d-8c43-45915cf0cac1',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'gbdt',\n",
       "               'colsample_bytree': 0.75,\n",
       "               'learning_rate': 0.1375,\n",
       "               'min_child_samples': 42,\n",
       "               'num_leaves': 26,\n",
       "               'reg_alpha': 0.5,\n",
       "               'reg_lambda': 0.5,\n",
       "               'subsample_for_bin': 51000}},\n",
       " { 'id': 'd8178825-25b5-4b97-9b77-1333c3f01314',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'gbdt',\n",
       "               'colsample_bytree': 0.75,\n",
       "               'learning_rate': 0.1375,\n",
       "               'min_child_samples': 42,\n",
       "               'num_leaves': 26,\n",
       "               'reg_alpha': 0.5,\n",
       "               'reg_lambda': 0.5,\n",
       "               'subsample': 1.0,\n",
       "               'subsample_for_bin': 51000}},\n",
       " { 'id': '813aad41-980c-49e6-9f4f-ad21cc5855ec',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'gbdt',\n",
       "               'colsample_bytree': 0.5384484771722862,\n",
       "               'learning_rate': 0.07395484122477124,\n",
       "               'min_child_samples': 58,\n",
       "               'num_leaves': 24,\n",
       "               'reg_alpha': 0.42344058704585485,\n",
       "               'reg_lambda': 0.5117182921782178,\n",
       "               'subsample_for_bin': 55019}},\n",
       " { 'id': 'd992ebf5-b50f-42ef-b4ea-c301d8bfe929',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'dart',\n",
       "               'colsample_bytree': 0.949883174845704,\n",
       "               'learning_rate': 0.04416961807698506,\n",
       "               'min_child_samples': 7,\n",
       "               'num_leaves': 36,\n",
       "               'reg_alpha': 0.47490107159901085,\n",
       "               'reg_lambda': 0.03559029863853691,\n",
       "               'subsample': 0.9997602142129441,\n",
       "               'subsample_for_bin': 13445}},\n",
       " { 'id': '50bb345f-2e7a-47f5-9ecd-ea24522f5c5b',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'dart',\n",
       "               'colsample_bytree': 0.9924585800917636,\n",
       "               'learning_rate': 0.0807613509312741,\n",
       "               'min_child_samples': 72,\n",
       "               'num_leaves': 34,\n",
       "               'reg_alpha': 0.31646131969889846,\n",
       "               'reg_lambda': 0.4537624502741342,\n",
       "               'subsample_for_bin': 50943}},\n",
       " { 'id': 'b28f6cbc-a719-4a98-ae1f-288c2780158b',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'dart',\n",
       "               'colsample_bytree': 0.7681991447683107,\n",
       "               'learning_rate': 0.11923406853106702,\n",
       "               'min_child_samples': 60,\n",
       "               'num_leaves': 29,\n",
       "               'reg_alpha': 0.7209728470349676,\n",
       "               'reg_lambda': 0.29397146082529513,\n",
       "               'subsample': 0.9828382588600002,\n",
       "               'subsample_for_bin': 5852}},\n",
       " { 'id': '15347116-060c-4c86-8512-80dd7863112d',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'gbdt',\n",
       "               'colsample_bytree': 0.9793190756801742,\n",
       "               'learning_rate': 0.09493702601166258,\n",
       "               'min_child_samples': 46,\n",
       "               'num_leaves': 8,\n",
       "               'reg_alpha': 0.7152716727555152,\n",
       "               'reg_lambda': 0.34476144671140907,\n",
       "               'subsample': 0.8054956186615145,\n",
       "               'subsample_for_bin': 15914}},\n",
       " { 'id': '0d4179f8-55fb-4b10-914a-7b10ec6ce5cc',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'gbdt',\n",
       "               'colsample_bytree': 0.7041515131434567,\n",
       "               'learning_rate': 0.030203278653882733,\n",
       "               'min_child_samples': 26,\n",
       "               'num_leaves': 47,\n",
       "               'reg_alpha': 0.7146802989418102,\n",
       "               'reg_lambda': 0.4736103979714489,\n",
       "               'subsample_for_bin': 65516}},\n",
       " { 'id': 'e2c5f1bb-4b1b-4d8e-b112-be669b4b61ae',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'dart',\n",
       "               'colsample_bytree': 0.9089987973229985,\n",
       "               'learning_rate': 0.15363516527458707,\n",
       "               'min_child_samples': 75,\n",
       "               'num_leaves': 27,\n",
       "               'reg_alpha': 0.5686478031133492,\n",
       "               'reg_lambda': 0.35954456855199546,\n",
       "               'subsample': 0.8453482570723153,\n",
       "               'subsample_for_bin': 59973}},\n",
       " { 'id': '732e6188-3f4c-4363-96b1-4df04fa9b629',\n",
       "   'type': 'exploration',\n",
       "   'values': { 'boosting_type': 'dart',\n",
       "               'colsample_bytree': 0.7923356229713168,\n",
       "               'learning_rate': 0.16460894604711096,\n",
       "               'min_child_samples': 76,\n",
       "               'num_leaves': 8,\n",
       "               'reg_alpha': 0.3349366261980846,\n",
       "               'reg_lambda': 0.18961391056009014,\n",
       "               'subsample_for_bin': 95071}}]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task.generate_configurations(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
